#!/usr/bin/env python3
"""
Comprehensive test suite for hybrid training
Tests all components to avoid runtime surprises
"""

import torch
import sys
from pathlib import Path

print("="*80)
print("HYBRID TRAINING TEST SUITE")
print("="*80)

# Test 1: Import all modules
print("\n[Test 1] Importing modules...")
try:
    from encodec import EncodecModel
    from adaptive_window_agent import AdaptiveWindowCreativeAgent
    from audio_discriminator import AudioDiscriminator
    from dataset_wav_pairs_24sec import AudioPairsDataset24sec, collate_fn
    from training.losses import rms_loss, combined_loss, spectral_outlier_penalty
    print("âœ… All imports successful")
except Exception as e:
    print(f"âŒ Import failed: {e}")
    sys.exit(1)

# Test 2: Dataset loading
print("\n[Test 2] Loading dataset...")
try:
    dataset = AudioPairsDataset24sec(
        data_folder='dataset_pairs_wav_24sec',
        split='train',
        target_sr=24000
    )
    print(f"âœ… Dataset loaded: {len(dataset)} pairs")
    
    # Test single sample
    audio_input, audio_target = dataset[0]
    print(f"   Input shape: {audio_input.shape}")
    print(f"   Target shape: {audio_target.shape}")
    assert audio_input.shape == (1, 576000), f"Wrong input shape: {audio_input.shape}"
    assert audio_target.shape == (1, 576000), f"Wrong target shape: {audio_target.shape}"
    print("âœ… Sample shapes correct: [1, 576000] (24 seconds @ 24kHz)")
except Exception as e:
    print(f"âŒ Dataset test failed: {e}")
    sys.exit(1)

# Test 3: EnCodec model
print("\n[Test 3] Loading EnCodec...")
try:
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"   Device: {device}")
    
    encodec_model = EncodecModel.encodec_model_24khz()
    encodec_model.set_target_bandwidth(6.0)
    encodec_model = encodec_model.to(device)
    encodec_model.eval()
    
    for param in encodec_model.parameters():
        param.requires_grad = False
    
    print("âœ… EnCodec loaded and frozen")
    
    # Test encoding
    test_audio = torch.randn(2, 1, 576000).to(device)  # Batch of 2
    with torch.no_grad():
        encoded = encodec_model.encoder(test_audio)
    print(f"   Encoded shape: {encoded.shape}")
    assert encoded.shape[0] == 2, f"Wrong batch size: {encoded.shape[0]}"
    assert encoded.shape[1] == 128, f"Wrong encoding dim: {encoded.shape[1]}"
    print(f"âœ… Encoding works: [2, 128, {encoded.shape[2]}]")
    
    # Test decoding
    with torch.no_grad():
        decoded = encodec_model.decoder(encoded)
    print(f"   Decoded shape: {decoded.shape}")
    assert decoded.shape == test_audio.shape, f"Decoded shape mismatch: {decoded.shape} vs {test_audio.shape}"
    print("âœ… Decoding works: [2, 1, 576000]")
    
except Exception as e:
    print(f"âŒ EnCodec test failed: {e}")
    sys.exit(1)

# Test 4: Adaptive Window Agent
print("\n[Test 4] Testing AdaptiveWindowCreativeAgent...")
try:
    model = AdaptiveWindowCreativeAgent(encoding_dim=128, num_pairs=3).to(device)
    model.eval()
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"   Total parameters: {total_params:,}")
    print(f"   Trainable parameters: {trainable_params:,}")
    print("âœ… Model initialized")
    
    # Test forward pass
    batch_size = 2
    with torch.no_grad():
        # Encode test audio
        test_input = torch.randn(batch_size, 1, 576000).to(device)
        test_target = torch.randn(batch_size, 1, 576000).to(device)
        
        encoded_input = encodec_model.encoder(test_input)
        encoded_target = encodec_model.encoder(test_target)
        
        print(f"   Input encoded: {encoded_input.shape}")
        print(f"   Target encoded: {encoded_target.shape}")
        
        # Forward through agent
        outputs_list, novelty_losses, metadata = model(encoded_input, encoded_target)
        
        print(f"   Number of outputs: {len(outputs_list)}")
        print(f"   Output 0 shape: {outputs_list[0].shape}")
        print(f"   Number of novelty losses: {len(novelty_losses)}")
        print(f"   Metadata keys: {list(metadata.keys())}")
        
        # Check output shapes
        for i, output in enumerate(outputs_list):
            assert output.shape == (batch_size, 128, 800), f"Output {i} wrong shape: {output.shape}"
        print("âœ… Forward pass successful: 3 outputs of [2, 128, 800]")
        
except Exception as e:
    print(f"âŒ Adaptive window agent test failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 5: Upsampling 800 â†’ 1200 frames
print("\n[Test 5] Testing upsampling (800 â†’ 1200 frames)...")
try:
    outputs_upsampled = []
    for output in outputs_list:
        B, D, T = output.shape
        print(f"   Input shape: [B={B}, D={D}, T={T}]")
        
        # Use adaptive_avg_pool1d for reliable upsampling
        output_reshaped = output.reshape(B * D, 1, T)  # [B*D, 1, 800]
        print(f"   Reshaped: {output_reshaped.shape}")
        
        output_upsampled = torch.nn.functional.adaptive_avg_pool1d(
            output_reshaped, output_size=1200
        )  # [B*D, 1, 1200]
        print(f"   Upsampled: {output_upsampled.shape}")
        
        output_1200 = output_upsampled.reshape(B, D, 1200)  # [B, 128, 1200]
        print(f"   Final: {output_1200.shape}")
        
        assert output_1200.shape == (batch_size, 128, 1200), f"Wrong upsampled shape: {output_1200.shape}"
        outputs_upsampled.append(output_1200)
    
    # Average outputs
    encoded_output = torch.stack(outputs_upsampled, dim=0).mean(dim=0)
    print(f"   Averaged shape: {encoded_output.shape}")
    assert encoded_output.shape == (batch_size, 128, 1200), f"Wrong averaged shape: {encoded_output.shape}"
    print("âœ… Upsampling successful: [2, 128, 800] â†’ [2, 128, 1200]")
    
except Exception as e:
    print(f"âŒ Upsampling test failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 6: Decoding upsampled output
print("\n[Test 6] Testing decoding upsampled output...")
try:
    with torch.no_grad():
        output_audio = encodec_model.decoder(encoded_output.detach())
        input_audio = encodec_model.decoder(encoded_input.detach())
    
    print(f"   Output audio shape: {output_audio.shape}")
    print(f"   Input audio shape: {input_audio.shape}")
    
    assert output_audio.shape == (batch_size, 1, 576000), f"Wrong output audio shape: {output_audio.shape}"
    assert input_audio.shape == (batch_size, 1, 576000), f"Wrong input audio shape: {input_audio.shape}"
    print("âœ… Decoding successful: [2, 128, 1200] â†’ [2, 1, 576000]")
    
except Exception as e:
    print(f"âŒ Decoding test failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 7: Loss computation
print("\n[Test 7] Testing loss computation...")
try:
    # Create fake target audio with correct shape
    target_audio = torch.randn(batch_size, 1, 576000).to(device)
    
    loss, rms_input, rms_target, spec, mel, corr = combined_loss(
        output_audio, input_audio, target_audio,
        weight_input=0.3,
        weight_target=0.3,
        weight_spectral=0.01,
        weight_mel=0.01,
        weight_correlation=0.5
    )
    
    print(f"   Loss: {loss.item():.6f}")
    print(f"   RMS input: {rms_input:.6f}" if isinstance(rms_input, float) else f"   RMS input: {rms_input.item():.6f}")
    print(f"   RMS target: {rms_target:.6f}" if isinstance(rms_target, float) else f"   RMS target: {rms_target.item():.6f}")
    print(f"   Spectral: {spec:.6f}" if isinstance(spec, float) else f"   Spectral: {spec.item():.6f}")
    print(f"   Mel: {mel:.6f}" if isinstance(mel, float) else f"   Mel: {mel.item():.6f}")
    print(f"   Correlation: {corr:.6f}" if isinstance(corr, float) else f"   Correlation: {corr.item():.6f}")
    
    assert not torch.isnan(loss), "Loss is NaN!"
    assert not torch.isinf(loss), "Loss is Inf!"
    print("âœ… Loss computation successful")
    
except Exception as e:
    print(f"âŒ Loss computation failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 8: GAN Discriminator
print("\n[Test 8] Testing AudioDiscriminator...")
try:
    discriminator = AudioDiscriminator(encoding_dim=128).to(device)
    discriminator.eval()
    
    disc_params = sum(p.numel() for p in discriminator.parameters())
    print(f"   Discriminator parameters: {disc_params:,}")
    
    # Test forward pass
    with torch.no_grad():
        # Use encoded output [B, D, T] where T can be 800 or 1200
        fake_logits = discriminator(encoded_output[:, :, :800])  # Use first 800 frames
        real_logits = discriminator(encoded_target[:, :, :800])
    
    print(f"   Fake logits shape: {fake_logits.shape}")
    print(f"   Real logits shape: {real_logits.shape}")
    assert fake_logits.shape == (batch_size, 1), f"Wrong fake logits shape: {fake_logits.shape}"
    assert real_logits.shape == (batch_size, 1), f"Wrong real logits shape: {real_logits.shape}"
    print("âœ… Discriminator forward pass successful")
    
except Exception as e:
    print(f"âŒ Discriminator test failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 9: Backward pass
print("\n[Test 9] Testing backward pass...")
try:
    model.train()
    discriminator.train()
    
    # Create optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    disc_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=5e-5)
    
    # Forward pass with gradients
    encoded_input_grad = encodec_model.encoder(test_input)
    encoded_target_grad = encodec_model.encoder(test_target)
    
    outputs_list, novelty_losses, metadata = model(encoded_input_grad, encoded_target_grad)
    
    # Upsample using adaptive pooling
    outputs_upsampled = []
    for output in outputs_list:
        B, D, T = output.shape
        output_reshaped = output.reshape(B * D, 1, T)
        output_upsampled = torch.nn.functional.adaptive_avg_pool1d(
            output_reshaped, output_size=1200
        )
        output_1200 = output_upsampled.reshape(B, D, 1200)
        outputs_upsampled.append(output_1200)
    
    encoded_output_grad = torch.stack(outputs_upsampled, dim=0).mean(dim=0)
    
    # Decode (with no_grad to avoid RNN backward error)
    with torch.no_grad():
        output_audio = encodec_model.decoder(encoded_output_grad.detach())
        input_audio = encodec_model.decoder(encoded_input_grad.detach())
    
    # Loss
    loss, rms_in, rms_tgt, spec, mel, corr = combined_loss(
        output_audio, input_audio, target_audio,
        0.3, 0.3, 0.01, 0.01, 0.5
    )
    
    # Add novelty loss
    mean_novelty = torch.stack(novelty_losses).mean()
    loss = loss + 0.1 * mean_novelty
    
    # Backward
    optimizer.zero_grad()
    loss.backward()
    
    # Check gradients
    has_grad = False
    for name, param in model.named_parameters():
        if param.grad is not None and param.grad.abs().sum() > 0:
            has_grad = True
            break
    
    assert has_grad, "No gradients computed!"
    print("âœ… Backward pass successful - gradients computed")
    
    # Optimizer step
    optimizer.step()
    print("âœ… Optimizer step successful")
    
except Exception as e:
    print(f"âŒ Backward pass test failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 10: DataLoader with collate_fn
print("\n[Test 10] Testing DataLoader...")
try:
    from torch.utils.data import DataLoader
    
    dataloader = DataLoader(
        dataset,
        batch_size=4,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=0  # Use 0 for testing
    )
    
    # Get one batch
    audio_inputs, audio_targets = next(iter(dataloader))
    print(f"   Batch input shape: {audio_inputs.shape}")
    print(f"   Batch target shape: {audio_targets.shape}")
    assert audio_inputs.shape == (4, 1, 576000), f"Wrong batch input shape: {audio_inputs.shape}"
    assert audio_targets.shape == (4, 1, 576000), f"Wrong batch target shape: {audio_targets.shape}"
    print("âœ… DataLoader successful: batch shape [4, 1, 576000]")
    
except Exception as e:
    print(f"âŒ DataLoader test failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Summary
print("\n" + "="*80)
print("âœ… ALL TESTS PASSED!")
print("="*80)
print("\nComponents verified:")
print("  âœ“ Module imports")
print("  âœ“ Dataset loading (24-second audio pairs)")
print("  âœ“ EnCodec encoder/decoder (freeze, forward)")
print("  âœ“ AdaptiveWindowCreativeAgent (3 window pairs)")
print("  âœ“ Upsampling (800 â†’ 1200 frames)")
print("  âœ“ Decoding (1200 frames â†’ 576k samples)")
print("  âœ“ Loss computation (RMS, spectral, mel, correlation)")
print("  âœ“ GAN discriminator")
print("  âœ“ Backward pass & gradients")
print("  âœ“ DataLoader with collate_fn")
print("\nğŸš€ Ready for full training!")
print("="*80)
